{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f553d5c3-1aba-4156-8265-826931f972dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "t = 4 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1f15450-80e6-468d-a81b-afe2fb314c56",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Przygotowanie środowiska"
    }
   },
   "outputs": [],
   "source": [
    "# Import functions\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "# Define variables used in code below\n",
    "file_path = \"/FileStore/stream/events/\"\n",
    "username = spark.sql(\"SELECT regexp_replace(current_user(), '[^a-zA-Z0-9]', '_')\").first()[0]\n",
    "table_name = f\"{username}_etl_quickstart\"\n",
    "checkpoint_path = f\"/tmp/{username}/_checkpoint/etl_quickstart\"\n",
    "\n",
    "# Clear out data from previous demo execution\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "dbutils.fs.rm(checkpoint_path, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de6cd530-5127-4c5f-a36e-dca868b3436f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(f\"dbfs:/user/hive/warehouse/{username}_etl_quickstart\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7add7a-ca44-4a1a-9c99-54130d587b5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /databricks-datasets/structured-streaming/events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e3f5fff-0a33-47bb-a578-a9663538ca45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Żeby sprawdzić czy stream działa kopjuj po jednym bądź kilku plikach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a32b8f-5771-42f5-b260-64349d507957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\"/databricks-datasets/structured-streaming/events/file-4.json\",\"/FileStore/stream/events/file-4.json\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49be85fe-7012-42b4-89d6-5bb3613482ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/stream/events/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6512dfcb-0dff-45aa-939e-53d8494eb586",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.format(\"json\").load(\"dbfs:/FileStore/stream/events/\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e2e489c-ad7a-49e3-801f-6f9268a9647b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dokończyć kod autoloadera \n",
    "1. Dodaj opcje 'cloudfiles'\n",
    "2. Dodaj kolumnę z metadanych 'source_file'\n",
    "3. Dane zapisać do tabeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9091358c-ab7a-4b63-94a8-24594344d4d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "(spark.readStream\n",
    "  .format(\"cloudFiles\")  \n",
    "  .option(\"cloudFiles.format\", \"json\")  \n",
    "  .load(file_path) \n",
    "\n",
    "  #  Dodaj kolumnę z metadanych\n",
    "  .withColumn(\"source_file\", input_file_name())\n",
    "\n",
    "  # Zapisz dane do tabeli\n",
    "  .writeStream\n",
    "  .option(\"checkpointLocation\", checkpoint_path)\n",
    "  .trigger(availableNow=True)\n",
    "  .toTable(table_name)  # zapis jako tabela zarządzana przez Spark\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dab3ddba-a9f9-4d97-a413-2376a38a9b6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(f\"select count(*) from {table_name}\")\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c57b7e7a-ec13-42ef-ae8c-704021be3209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Sprawdzć metadane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bce06416-61c8-4364-b2e3-74af2d0a3db7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"/tmp/{username}/_checkpoint/etl_quickstart/sources/0/metadata/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95f19fe2-bf28-436a-a42c-648e5498160a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /tmp/{user}/_checkpoint/etl_quickstart/metadata"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1938775723195116,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Autoloader",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}